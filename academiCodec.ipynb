{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Fake Audio using AcademiCodec: https://github.com/yangdongchao/AcademiCodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo path added to sys.path: /data/lekha_codec_model_files/AcademiCodec/\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the AcademicCodec repository to the Python path\n",
    "repo_path = \"/data/lekha_codec_model_files/AcademiCodec/\"\n",
    "sys.path.append(repo_path)\n",
    "\n",
    "# Verify if the path is correctly added\n",
    "print(\"Repo path added to sys.path:\", repo_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1110688/3966053141.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vqvae.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VQVAE:\n\tMissing key(s) in state_dict: \"quantizer.quantizer_modules.0.embedding.weight\", \"quantizer.quantizer_modules.1.embedding.weight\", \"quantizer.quantizer_modules2.0.embedding.weight\", \"quantizer.quantizer_modules2.1.embedding.weight\", \"generator.conv_pre.bias\", \"generator.conv_pre.weight_g\", \"generator.conv_pre.weight_v\", \"generator.ups.0.bias\", \"generator.ups.0.weight_g\", \"generator.ups.0.weight_v\", \"generator.ups.1.bias\", \"generator.ups.1.weight_g\", \"generator.ups.1.weight_v\", \"generator.ups.2.bias\", \"generator.ups.2.weight_g\", \"generator.ups.2.weight_v\", \"generator.ups.3.bias\", \"generator.ups.3.weight_g\", \"generator.ups.3.weight_v\", \"generator.resblocks.0.convs1.0.bias\", \"generator.resblocks.0.convs1.0.weight_g\", \"generator.resblocks.0.convs1.0.weight_v\", \"generator.resblocks.0.convs1.1.bias\", \"generator.resblocks.0.convs1.1.weight_g\", \"generator.resblocks.0.convs1.1.weight_v\", \"generator.resblocks.0.convs1.2.bias\", \"generator.resblocks.0.convs1.2.weight_g\", \"generator.resblocks.0.convs1.2.weight_v\", \"generator.resblocks.0.convs2.0.bias\", \"generator.resblocks.0.convs2.0.weight_g\", \"generator.resblocks.0.convs2.0.weight_v\", \"generator.resblocks.0.convs2.1.bias\", \"generator.resblocks.0.convs2.1.weight_g\", \"generator.resblocks.0.convs2.1.weight_v\", \"generator.resblocks.0.convs2.2.bias\", \"generator.resblocks.0.convs2.2.weight_g\", \"generator.resblocks.0.convs2.2.weight_v\", \"generator.resblocks.1.convs1.0.bias\", \"generator.resblocks.1.convs1.0.weight_g\", \"generator.resblocks.1.convs1.0.weight_v\", \"generator.resblocks.1.convs1.1.bias\", \"generator.resblocks.1.convs1.1.weight_g\", \"generator.resblocks.1.convs1.1.weight_v\", \"generator.resblocks.1.convs1.2.bias\", \"generator.resblocks.1.convs1.2.weight_g\", \"generator.resblocks.1.convs1.2.weight_v\", \"generator.resblocks.1.convs2.0.bias\", \"generator.resblocks.1.convs2.0.weight_g\", \"generator.resblocks.1.convs2.0.weight_v\", \"generator.resblocks.1.convs2.1.bias\", \"generator.resblocks.1.convs2.1.weight_g\", \"generator.resblocks.1.convs2.1.weight_v\", \"generator.resblocks.1.convs2.2.bias\", \"generator.resblocks.1.convs2.2.weight_g\", \"generator.resblocks.1.convs2.2.weight_v\", \"generator.resblocks.2.convs1.0.bias\", \"generator.resblocks.2.convs1.0.weight_g\", \"generator.resblocks.2.convs1.0.weight_v\", \"generator.resblocks.2.convs1.1.bias\", \"generator.resblocks.2.convs1.1.weight_g\", \"generator.resblocks.2.convs1.1.weight_v\", \"generator.resblocks.2.convs1.2.bias\", \"generator.resblocks.2.convs1.2.weight_g\", \"generator.resblocks.2.convs1.2.weight_v\", \"generator.resblocks.2.convs2.0.bias\", \"generator.resblocks.2.convs2.0.weight_g\", \"generator.resblocks.2.convs2.0.weight_v\", \"generator.resblocks.2.convs2.1.bias\", \"generator.resblocks.2.convs2.1.weight_g\", \"generator.resblocks.2.convs2.1.weight_v\", \"generator.resblocks.2.convs2.2.bias\", \"generator.resblocks.2.convs2.2.weight_g\", \"generator.resblocks.2.convs2.2.weight_v\", \"generator.resblocks.3.convs1.0.bias\", \"generator.resblocks.3.convs1.0.weight_g\", \"generator.resblocks.3.convs1.0.weight_v\", \"generator.resblocks.3.convs1.1.bias\", \"generator.resblocks.3.convs1.1.weight_g\", \"generator.resblocks.3.convs1.1.weight_v\", \"generator.resblocks.3.convs1.2.bias\", \"generator.resblocks.3.convs1.2.weight_g\", \"generator.resblocks.3.convs1.2.weight_v\", \"generator.resblocks.3.convs2.0.bias\", \"generator.resblocks.3.convs2.0.weight_g\", \"generator.resblocks.3.convs2.0.weight_v\", \"generator.resblocks.3.convs2.1.bias\", \"generator.resblocks.3.convs2.1.weight_g\", \"generator.resblocks.3.convs2.1.weight_v\", \"generator.resblocks.3.convs2.2.bias\", \"generator.resblocks.3.convs2.2.weight_g\", \"generator.resblocks.3.convs2.2.weight_v\", \"generator.resblocks.4.convs1.0.bias\", \"generator.resblocks.4.convs1.0.weight_g\", \"generator.resblocks.4.convs1.0.weight_v\", \"generator.resblocks.4.convs1.1.bias\", \"generator.resblocks.4.convs1.1.weight_g\", \"generator.resblocks.4.convs1.1.weight_v\", \"generator.resblocks.4.convs1.2.bias\", \"generator.resblocks.4.convs1.2.weight_g\", \"generator.resblocks.4.convs1.2.weight_v\", \"generator.resblocks.4.convs2.0.bias\", \"generator.resblocks.4.convs2.0.weight_g\", \"generator.resblocks.4.convs2.0.weight_v\", \"generator.resblocks.4.convs2.1.bias\", \"generator.resblocks.4.convs2.1.weight_g\", \"generator.resblocks.4.convs2.1.weight_v\", \"generator.resblocks.4.convs2.2.bias\", \"generator.resblocks.4.convs2.2.weight_g\", \"generator.resblocks.4.convs2.2.weight_v\", \"generator.resblocks.5.convs1.0.bias\", \"generator.resblocks.5.convs1.0.weight_g\", \"generator.resblocks.5.convs1.0.weight_v\", \"generator.resblocks.5.convs1.1.bias\", \"generator.resblocks.5.convs1.1.weight_g\", \"generator.resblocks.5.convs1.1.weight_v\", \"generator.resblocks.5.convs1.2.bias\", \"generator.resblocks.5.convs1.2.weight_g\", \"generator.resblocks.5.convs1.2.weight_v\", \"generator.resblocks.5.convs2.0.bias\", \"generator.resblocks.5.convs2.0.weight_g\", \"generator.resblocks.5.convs2.0.weight_v\", \"generator.resblocks.5.convs2.1.bias\", \"generator.resblocks.5.convs2.1.weight_g\", \"generator.resblocks.5.convs2.1.weight_v\", \"generator.resblocks.5.convs2.2.bias\", \"generator.resblocks.5.convs2.2.weight_g\", \"generator.resblocks.5.convs2.2.weight_v\", \"generator.resblocks.6.convs1.0.bias\", \"generator.resblocks.6.convs1.0.weight_g\", \"generator.resblocks.6.convs1.0.weight_v\", \"generator.resblocks.6.convs1.1.bias\", \"generator.resblocks.6.convs1.1.weight_g\", \"generator.resblocks.6.convs1.1.weight_v\", \"generator.resblocks.6.convs1.2.bias\", \"generator.resblocks.6.convs1.2.weight_g\", \"generator.resblocks.6.convs1.2.weight_v\", \"generator.resblocks.6.convs2.0.bias\", \"generator.resblocks.6.convs2.0.weight_g\", \"generator.resblocks.6.convs2.0.weight_v\", \"generator.resblocks.6.convs2.1.bias\", \"generator.resblocks.6.convs2.1.weight_g\", \"generator.resblocks.6.convs2.1.weight_v\", \"generator.resblocks.6.convs2.2.bias\", \"generator.resblocks.6.convs2.2.weight_g\", \"generator.resblocks.6.convs2.2.weight_v\", \"generator.resblocks.7.convs1.0.bias\", \"generator.resblocks.7.convs1.0.weight_g\", \"generator.resblocks.7.convs1.0.weight_v\", \"generator.resblocks.7.convs1.1.bias\", \"generator.resblocks.7.convs1.1.weight_g\", \"generator.resblocks.7.convs1.1.weight_v\", \"generator.resblocks.7.convs1.2.bias\", \"generator.resblocks.7.convs1.2.weight_g\", \"generator.resblocks.7.convs1.2.weight_v\", \"generator.resblocks.7.convs2.0.bias\", \"generator.resblocks.7.convs2.0.weight_g\", \"generator.resblocks.7.convs2.0.weight_v\", \"generator.resblocks.7.convs2.1.bias\", \"generator.resblocks.7.convs2.1.weight_g\", \"generator.resblocks.7.convs2.1.weight_v\", \"generator.resblocks.7.convs2.2.bias\", \"generator.resblocks.7.convs2.2.weight_g\", \"generator.resblocks.7.convs2.2.weight_v\", \"generator.resblocks.8.convs1.0.bias\", \"generator.resblocks.8.convs1.0.weight_g\", \"generator.resblocks.8.convs1.0.weight_v\", \"generator.resblocks.8.convs1.1.bias\", \"generator.resblocks.8.convs1.1.weight_g\", \"generator.resblocks.8.convs1.1.weight_v\", \"generator.resblocks.8.convs1.2.bias\", \"generator.resblocks.8.convs1.2.weight_g\", \"generator.resblocks.8.convs1.2.weight_v\", \"generator.resblocks.8.convs2.0.bias\", \"generator.resblocks.8.convs2.0.weight_g\", \"generator.resblocks.8.convs2.0.weight_v\", \"generator.resblocks.8.convs2.1.bias\", \"generator.resblocks.8.convs2.1.weight_g\", \"generator.resblocks.8.convs2.1.weight_v\", \"generator.resblocks.8.convs2.2.bias\", \"generator.resblocks.8.convs2.2.weight_g\", \"generator.resblocks.8.convs2.2.weight_v\", \"generator.resblocks.9.convs1.0.bias\", \"generator.resblocks.9.convs1.0.weight_g\", \"generator.resblocks.9.convs1.0.weight_v\", \"generator.resblocks.9.convs1.1.bias\", \"generator.resblocks.9.convs1.1.weight_g\", \"generator.resblocks.9.convs1.1.weight_v\", \"generator.resblocks.9.convs1.2.bias\", \"generator.resblocks.9.convs1.2.weight_g\", \"generator.resblocks.9.convs1.2.weight_v\", \"generator.resblocks.9.convs2.0.bias\", \"generator.resblocks.9.convs2.0.weight_g\", \"generator.resblocks.9.convs2.0.weight_v\", \"generator.resblocks.9.convs2.1.bias\", \"generator.resblocks.9.convs2.1.weight_g\", \"generator.resblocks.9.convs2.1.weight_v\", \"generator.resblocks.9.convs2.2.bias\", \"generator.resblocks.9.convs2.2.weight_g\", \"generator.resblocks.9.convs2.2.weight_v\", \"generator.resblocks.10.convs1.0.bias\", \"generator.resblocks.10.convs1.0.weight_g\", \"generator.resblocks.10.convs1.0.weight_v\", \"generator.resblocks.10.convs1.1.bias\", \"generator.resblocks.10.convs1.1.weight_g\", \"generator.resblocks.10.convs1.1.weight_v\", \"generator.resblocks.10.convs1.2.bias\", \"generator.resblocks.10.convs1.2.weight_g\", \"generator.resblocks.10.convs1.2.weight_v\", \"generator.resblocks.10.convs2.0.bias\", \"generator.resblocks.10.convs2.0.weight_g\", \"generator.resblocks.10.convs2.0.weight_v\", \"generator.resblocks.10.convs2.1.bias\", \"generator.resblocks.10.convs2.1.weight_g\", \"generator.resblocks.10.convs2.1.weight_v\", \"generator.resblocks.10.convs2.2.bias\", \"generator.resblocks.10.convs2.2.weight_g\", \"generator.resblocks.10.convs2.2.weight_v\", \"generator.resblocks.11.convs1.0.bias\", \"generator.resblocks.11.convs1.0.weight_g\", \"generator.resblocks.11.convs1.0.weight_v\", \"generator.resblocks.11.convs1.1.bias\", \"generator.resblocks.11.convs1.1.weight_g\", \"generator.resblocks.11.convs1.1.weight_v\", \"generator.resblocks.11.convs1.2.bias\", \"generator.resblocks.11.convs1.2.weight_g\", \"generator.resblocks.11.convs1.2.weight_v\", \"generator.resblocks.11.convs2.0.bias\", \"generator.resblocks.11.convs2.0.weight_g\", \"generator.resblocks.11.convs2.0.weight_v\", \"generator.resblocks.11.convs2.1.bias\", \"generator.resblocks.11.convs2.1.weight_g\", \"generator.resblocks.11.convs2.1.weight_v\", \"generator.resblocks.11.convs2.2.bias\", \"generator.resblocks.11.convs2.2.weight_g\", \"generator.resblocks.11.convs2.2.weight_v\", \"generator.conv_post.bias\", \"generator.conv_post.weight_g\", \"generator.conv_post.weight_v\", \"encoder.conv_pre.bias\", \"encoder.conv_pre.weight_g\", \"encoder.conv_pre.weight_v\", \"encoder.normalize.0.weight\", \"encoder.normalize.0.bias\", \"encoder.normalize.1.weight\", \"encoder.normalize.1.bias\", \"encoder.normalize.2.weight\", \"encoder.normalize.2.bias\", \"encoder.normalize.3.weight\", \"encoder.normalize.3.bias\", \"encoder.normalize.4.weight\", \"encoder.normalize.4.bias\", \"encoder.normalize.5.weight\", \"encoder.normalize.5.bias\", \"encoder.normalize.6.weight\", \"encoder.normalize.6.bias\", \"encoder.normalize.7.weight\", \"encoder.normalize.7.bias\", \"encoder.normalize.8.weight\", \"encoder.normalize.8.bias\", \"encoder.normalize.9.weight\", \"encoder.normalize.9.bias\", \"encoder.normalize.10.weight\", \"encoder.normalize.10.bias\", \"encoder.normalize.11.weight\", \"encoder.normalize.11.bias\", \"encoder.ups.0.bias\", \"encoder.ups.0.weight_g\", \"encoder.ups.0.weight_v\", \"encoder.ups.1.bias\", \"encoder.ups.1.weight_g\", \"encoder.ups.1.weight_v\", \"encoder.ups.2.bias\", \"encoder.ups.2.weight_g\", \"encoder.ups.2.weight_v\", \"encoder.ups.3.bias\", \"encoder.ups.3.weight_g\", \"encoder.ups.3.weight_v\", \"encoder.resblocks.0.convs1.0.bias\", \"encoder.resblocks.0.convs1.0.weight_g\", \"encoder.resblocks.0.convs1.0.weight_v\", \"encoder.resblocks.0.convs1.1.bias\", \"encoder.resblocks.0.convs1.1.weight_g\", \"encoder.resblocks.0.convs1.1.weight_v\", \"encoder.resblocks.0.convs1.2.bias\", \"encoder.resblocks.0.convs1.2.weight_g\", \"encoder.resblocks.0.convs1.2.weight_v\", \"encoder.resblocks.0.convs2.0.bias\", \"encoder.resblocks.0.convs2.0.weight_g\", \"encoder.resblocks.0.convs2.0.weight_v\", \"encoder.resblocks.0.convs2.1.bias\", \"encoder.resblocks.0.convs2.1.weight_g\", \"encoder.resblocks.0.convs2.1.weight_v\", \"encoder.resblocks.0.convs2.2.bias\", \"encoder.resblocks.0.convs2.2.weight_g\", \"encoder.resblocks.0.convs2.2.weight_v\", \"encoder.resblocks.1.convs1.0.bias\", \"encoder.resblocks.1.convs1.0.weight_g\", \"encoder.resblocks.1.convs1.0.weight_v\", \"encoder.resblocks.1.convs1.1.bias\", \"encoder.resblocks.1.convs1.1.weight_g\", \"encoder.resblocks.1.convs1.1.weight_v\", \"encoder.resblocks.1.convs1.2.bias\", \"encoder.resblocks.1.convs1.2.weight_g\", \"encoder.resblocks.1.convs1.2.weight_v\", \"encoder.resblocks.1.convs2.0.bias\", \"encoder.resblocks.1.convs2.0.weight_g\", \"encoder.resblocks.1.convs2.0.weight_v\", \"encoder.resblocks.1.convs2.1.bias\", \"encoder.resblocks.1.convs2.1.weight_g\", \"encoder.resblocks.1.convs2.1.weight_v\", \"encoder.resblocks.1.convs2.2.bias\", \"encoder.resblocks.1.convs2.2.weight_g\", \"encoder.resblocks.1.convs2.2.weight_v\", \"encoder.resblocks.2.convs1.0.bias\", \"encoder.resblocks.2.convs1.0.weight_g\", \"encoder.resblocks.2.convs1.0.weight_v\", \"encoder.resblocks.2.convs1.1.bias\", \"encoder.resblocks.2.convs1.1.weight_g\", \"encoder.resblocks.2.convs1.1.weight_v\", \"encoder.resblocks.2.convs1.2.bias\", \"encoder.resblocks.2.convs1.2.weight_g\", \"encoder.resblocks.2.convs1.2.weight_v\", \"encoder.resblocks.2.convs2.0.bias\", \"encoder.resblocks.2.convs2.0.weight_g\", \"encoder.resblocks.2.convs2.0.weight_v\", \"encoder.resblocks.2.convs2.1.bias\", \"encoder.resblocks.2.convs2.1.weight_g\", \"encoder.resblocks.2.convs2.1.weight_v\", \"encoder.resblocks.2.convs2.2.bias\", \"encoder.resblocks.2.convs2.2.weight_g\", \"encoder.resblocks.2.convs2.2.weight_v\", \"encoder.resblocks.3.convs1.0.bias\", \"encoder.resblocks.3.convs1.0.weight_g\", \"encoder.resblocks.3.convs1.0.weight_v\", \"encoder.resblocks.3.convs1.1.bias\", \"encoder.resblocks.3.convs1.1.weight_g\", \"encoder.resblocks.3.convs1.1.weight_v\", \"encoder.resblocks.3.convs1.2.bias\", \"encoder.resblocks.3.convs1.2.weight_g\", \"encoder.resblocks.3.convs1.2.weight_v\", \"encoder.resblocks.3.convs2.0.bias\", \"encoder.resblocks.3.convs2.0.weight_g\", \"encoder.resblocks.3.convs2.0.weight_v\", \"encoder.resblocks.3.convs2.1.bias\", \"encoder.resblocks.3.convs2.1.weight_g\", \"encoder.resblocks.3.convs2.1.weight_v\", \"encoder.resblocks.3.convs2.2.bias\", \"encoder.resblocks.3.convs2.2.weight_g\", \"encoder.resblocks.3.convs2.2.weight_v\", \"encoder.resblocks.4.convs1.0.bias\", \"encoder.resblocks.4.convs1.0.weight_g\", \"encoder.resblocks.4.convs1.0.weight_v\", \"encoder.resblocks.4.convs1.1.bias\", \"encoder.resblocks.4.convs1.1.weight_g\", \"encoder.resblocks.4.convs1.1.weight_v\", \"encoder.resblocks.4.convs1.2.bias\", \"encoder.resblocks.4.convs1.2.weight_g\", \"encoder.resblocks.4.convs1.2.weight_v\", \"encoder.resblocks.4.convs2.0.bias\", \"encoder.resblocks.4.convs2.0.weight_g\", \"encoder.resblocks.4.convs2.0.weight_v\", \"encoder.resblocks.4.convs2.1.bias\", \"encoder.resblocks.4.convs2.1.weight_g\", \"encoder.resblocks.4.convs2.1.weight_v\", \"encoder.resblocks.4.convs2.2.bias\", \"encoder.resblocks.4.convs2.2.weight_g\", \"encoder.resblocks.4.convs2.2.weight_v\", \"encoder.resblocks.5.convs1.0.bias\", \"encoder.resblocks.5.convs1.0.weight_g\", \"encoder.resblocks.5.convs1.0.weight_v\", \"encoder.resblocks.5.convs1.1.bias\", \"encoder.resblocks.5.convs1.1.weight_g\", \"encoder.resblocks.5.convs1.1.weight_v\", \"encoder.resblocks.5.convs1.2.bias\", \"encoder.resblocks.5.convs1.2.weight_g\", \"encoder.resblocks.5.convs1.2.weight_v\", \"encoder.resblocks.5.convs2.0.bias\", \"encoder.resblocks.5.convs2.0.weight_g\", \"encoder.resblocks.5.convs2.0.weight_v\", \"encoder.resblocks.5.convs2.1.bias\", \"encoder.resblocks.5.convs2.1.weight_g\", \"encoder.resblocks.5.convs2.1.weight_v\", \"encoder.resblocks.5.convs2.2.bias\", \"encoder.resblocks.5.convs2.2.weight_g\", \"encoder.resblocks.5.convs2.2.weight_v\", \"encoder.resblocks.6.convs1.0.bias\", \"encoder.resblocks.6.convs1.0.weight_g\", \"encoder.resblocks.6.convs1.0.weight_v\", \"encoder.resblocks.6.convs1.1.bias\", \"encoder.resblocks.6.convs1.1.weight_g\", \"encoder.resblocks.6.convs1.1.weight_v\", \"encoder.resblocks.6.convs1.2.bias\", \"encoder.resblocks.6.convs1.2.weight_g\", \"encoder.resblocks.6.convs1.2.weight_v\", \"encoder.resblocks.6.convs2.0.bias\", \"encoder.resblocks.6.convs2.0.weight_g\", \"encoder.resblocks.6.convs2.0.weight_v\", \"encoder.resblocks.6.convs2.1.bias\", \"encoder.resblocks.6.convs2.1.weight_g\", \"encoder.resblocks.6.convs2.1.weight_v\", \"encoder.resblocks.6.convs2.2.bias\", \"encoder.resblocks.6.convs2.2.weight_g\", \"encoder.resblocks.6.convs2.2.weight_v\", \"encoder.resblocks.7.convs1.0.bias\", \"encoder.resblocks.7.convs1.0.weight_g\", \"encoder.resblocks.7.convs1.0.weight_v\", \"encoder.resblocks.7.convs1.1.bias\", \"encoder.resblocks.7.convs1.1.weight_g\", \"encoder.resblocks.7.convs1.1.weight_v\", \"encoder.resblocks.7.convs1.2.bias\", \"encoder.resblocks.7.convs1.2.weight_g\", \"encoder.resblocks.7.convs1.2.weight_v\", \"encoder.resblocks.7.convs2.0.bias\", \"encoder.resblocks.7.convs2.0.weight_g\", \"encoder.resblocks.7.convs2.0.weight_v\", \"encoder.resblocks.7.convs2.1.bias\", \"encoder.resblocks.7.convs2.1.weight_g\", \"encoder.resblocks.7.convs2.1.weight_v\", \"encoder.resblocks.7.convs2.2.bias\", \"encoder.resblocks.7.convs2.2.weight_g\", \"encoder.resblocks.7.convs2.2.weight_v\", \"encoder.resblocks.8.convs1.0.bias\", \"encoder.resblocks.8.convs1.0.weight_g\", \"encoder.resblocks.8.convs1.0.weight_v\", \"encoder.resblocks.8.convs1.1.bias\", \"encoder.resblocks.8.convs1.1.weight_g\", \"encoder.resblocks.8.convs1.1.weight_v\", \"encoder.resblocks.8.convs1.2.bias\", \"encoder.resblocks.8.convs1.2.weight_g\", \"encoder.resblocks.8.convs1.2.weight_v\", \"encoder.resblocks.8.convs2.0.bias\", \"encoder.resblocks.8.convs2.0.weight_g\", \"encoder.resblocks.8.convs2.0.weight_v\", \"encoder.resblocks.8.convs2.1.bias\", \"encoder.resblocks.8.convs2.1.weight_g\", \"encoder.resblocks.8.convs2.1.weight_v\", \"encoder.resblocks.8.convs2.2.bias\", \"encoder.resblocks.8.convs2.2.weight_g\", \"encoder.resblocks.8.convs2.2.weight_v\", \"encoder.resblocks.9.convs1.0.bias\", \"encoder.resblocks.9.convs1.0.weight_g\", \"encoder.resblocks.9.convs1.0.weight_v\", \"encoder.resblocks.9.convs1.1.bias\", \"encoder.resblocks.9.convs1.1.weight_g\", \"encoder.resblocks.9.convs1.1.weight_v\", \"encoder.resblocks.9.convs1.2.bias\", \"encoder.resblocks.9.convs1.2.weight_g\", \"encoder.resblocks.9.convs1.2.weight_v\", \"encoder.resblocks.9.convs2.0.bias\", \"encoder.resblocks.9.convs2.0.weight_g\", \"encoder.resblocks.9.convs2.0.weight_v\", \"encoder.resblocks.9.convs2.1.bias\", \"encoder.resblocks.9.convs2.1.weight_g\", \"encoder.resblocks.9.convs2.1.weight_v\", \"encoder.resblocks.9.convs2.2.bias\", \"encoder.resblocks.9.convs2.2.weight_g\", \"encoder.resblocks.9.convs2.2.weight_v\", \"encoder.resblocks.10.convs1.0.bias\", \"encoder.resblocks.10.convs1.0.weight_g\", \"encoder.resblocks.10.convs1.0.weight_v\", \"encoder.resblocks.10.convs1.1.bias\", \"encoder.resblocks.10.convs1.1.weight_g\", \"encoder.resblocks.10.convs1.1.weight_v\", \"encoder.resblocks.10.convs1.2.bias\", \"encoder.resblocks.10.convs1.2.weight_g\", \"encoder.resblocks.10.convs1.2.weight_v\", \"encoder.resblocks.10.convs2.0.bias\", \"encoder.resblocks.10.convs2.0.weight_g\", \"encoder.resblocks.10.convs2.0.weight_v\", \"encoder.resblocks.10.convs2.1.bias\", \"encoder.resblocks.10.convs2.1.weight_g\", \"encoder.resblocks.10.convs2.1.weight_v\", \"encoder.resblocks.10.convs2.2.bias\", \"encoder.resblocks.10.convs2.2.weight_g\", \"encoder.resblocks.10.convs2.2.weight_v\", \"encoder.resblocks.11.convs1.0.bias\", \"encoder.resblocks.11.convs1.0.weight_g\", \"encoder.resblocks.11.convs1.0.weight_v\", \"encoder.resblocks.11.convs1.1.bias\", \"encoder.resblocks.11.convs1.1.weight_g\", \"encoder.resblocks.11.convs1.1.weight_v\", \"encoder.resblocks.11.convs1.2.bias\", \"encoder.resblocks.11.convs1.2.weight_g\", \"encoder.resblocks.11.convs1.2.weight_v\", \"encoder.resblocks.11.convs2.0.bias\", \"encoder.resblocks.11.convs2.0.weight_g\", \"encoder.resblocks.11.convs2.0.weight_v\", \"encoder.resblocks.11.convs2.1.bias\", \"encoder.resblocks.11.convs2.1.weight_g\", \"encoder.resblocks.11.convs2.1.weight_v\", \"encoder.resblocks.11.convs2.2.bias\", \"encoder.resblocks.11.convs2.2.weight_g\", \"encoder.resblocks.11.convs2.2.weight_v\", \"encoder.conv_post.weight\", \"encoder.conv_post.bias\". \n\tUnexpected key(s) in state_dict: \"generator\", \"encoder\", \"quantizer\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize the VQVAE model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m vqvae \u001b[38;5;241m=\u001b[39m VQVAE(config_path, model_path, with_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mvqvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m vqvae\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Input audio path\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/codec_fake/lib/python3.12/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VQVAE:\n\tMissing key(s) in state_dict: \"quantizer.quantizer_modules.0.embedding.weight\", \"quantizer.quantizer_modules.1.embedding.weight\", \"quantizer.quantizer_modules2.0.embedding.weight\", \"quantizer.quantizer_modules2.1.embedding.weight\", \"generator.conv_pre.bias\", \"generator.conv_pre.weight_g\", \"generator.conv_pre.weight_v\", \"generator.ups.0.bias\", \"generator.ups.0.weight_g\", \"generator.ups.0.weight_v\", \"generator.ups.1.bias\", \"generator.ups.1.weight_g\", \"generator.ups.1.weight_v\", \"generator.ups.2.bias\", \"generator.ups.2.weight_g\", \"generator.ups.2.weight_v\", \"generator.ups.3.bias\", \"generator.ups.3.weight_g\", \"generator.ups.3.weight_v\", \"generator.resblocks.0.convs1.0.bias\", \"generator.resblocks.0.convs1.0.weight_g\", \"generator.resblocks.0.convs1.0.weight_v\", \"generator.resblocks.0.convs1.1.bias\", \"generator.resblocks.0.convs1.1.weight_g\", \"generator.resblocks.0.convs1.1.weight_v\", \"generator.resblocks.0.convs1.2.bias\", \"generator.resblocks.0.convs1.2.weight_g\", \"generator.resblocks.0.convs1.2.weight_v\", \"generator.resblocks.0.convs2.0.bias\", \"generator.resblocks.0.convs2.0.weight_g\", \"generator.resblocks.0.convs2.0.weight_v\", \"generator.resblocks.0.convs2.1.bias\", \"generator.resblocks.0.convs2.1.weight_g\", \"generator.resblocks.0.convs2.1.weight_v\", \"generator.resblocks.0.convs2.2.bias\", \"generator.resblocks.0.convs2.2.weight_g\", \"generator.resblocks.0.convs2.2.weight_v\", \"generator.resblocks.1.convs1.0.bias\", \"generator.resblocks.1.convs1.0.weight_g\", \"generator.resblocks.1.convs1.0.weight_v\", \"generator.resblocks.1.convs1.1.bias\", \"generator.resblocks.1.convs1.1.weight_g\", \"generator.resblocks.1.convs1.1.weight_v\", \"generator.resblocks.1.convs1.2.bias\", \"generator.resblocks.1.convs1.2.weight_g\", \"generator.resblocks.1.convs1.2.weight_v\", \"generator.resblocks.1.convs2.0.bias\", \"generator.resblocks.1.convs2.0.weight_g\", \"generator.resblocks.1.convs2.0.weight_v\", \"generator.resblocks.1.convs2.1.bias\", \"generator.resblocks.1.convs2.1.weight_g\", \"generator.resblocks.1.convs2.1.weight_v\", \"generator.resblocks.1.convs2.2.bias\", \"generator.resblocks.1.convs2.2.weight_g\", \"generator.resblocks.1.convs2.2.weight_v\", \"generator.resblocks.2.convs1.0.bias\", \"generator.resblocks.2.convs1.0.weight_g\", \"generator.resblocks.2.convs1.0.weight_v\", \"generator.resblocks.2.convs1.1.bias\", \"generator.resblocks.2.convs1.1.weight_g\", \"generator.resblocks.2.convs1.1.weight_v\", \"generator.resblocks.2.convs1.2.bias\", \"generator.resblocks.2.convs1.2.weight_g\", \"generator.resblocks.2.convs1.2.weight_v\", \"generator.resblocks.2.convs2.0.bias\", \"generator.resblocks.2.convs2.0.weight_g\", \"generator.resblocks.2.convs2.0.weight_v\", \"generator.resblocks.2.convs2.1.bias\", \"generator.resblocks.2.convs2.1.weight_g\", \"generator.resblocks.2.convs2.1.weight_v\", \"generator.resblocks.2.convs2.2.bias\", \"generator.resblocks.2.convs2.2.weight_g\", \"generator.resblocks.2.convs2.2.weight_v\", \"generator.resblocks.3.convs1.0.bias\", \"generator.resblocks.3.convs1.0.weight_g\", \"generator.resblocks.3.convs1.0.weight_v\", \"generator.resblocks.3.convs1.1.bias\", \"generator.resblocks.3.convs1.1.weight_g\", \"generator.resblocks.3.convs1.1.weight_v\", \"generator.resblocks.3.convs1.2.bias\", \"generator.resblocks.3.convs1.2.weight_g\", \"generator.resblocks.3.convs1.2.weight_v\", \"generator.resblocks.3.convs2.0.bias\", \"generator.resblocks.3.convs2.0.weight_g\", \"generator.resblocks.3.convs2.0.weight_v\", \"generator.resblocks.3.convs2.1.bias\", \"generator.resblocks.3.convs2.1.weight_g\", \"generator.resblocks.3.convs2.1.weight_v\", \"generator.resblocks.3.convs2.2.bias\", \"generator.resblocks.3.convs2.2.weight_g\", \"generator.resblocks.3.convs2.2.weight_v\", \"generator.resblocks.4.convs1.0.bias\", \"generator.resblocks.4.convs1.0.weight_g\", \"generator.resblocks.4.convs1.0.weight_v\", \"generator.resblocks.4.convs1.1.bias\", \"generator.resblocks.4.convs1.1.weight_g\", \"generator.resblocks.4.convs1.1.weight_v\", \"generator.resblocks.4.convs1.2.bias\", \"generator.resblocks.4.convs1.2.weight_g\", \"generator.resblocks.4.convs1.2.weight_v\", \"generator.resblocks.4.convs2.0.bias\", \"generator.resblocks.4.convs2.0.weight_g\", \"generator.resblocks.4.convs2.0.weight_v\", \"generator.resblocks.4.convs2.1.bias\", \"generator.resblocks.4.convs2.1.weight_g\", \"generator.resblocks.4.convs2.1.weight_v\", \"generator.resblocks.4.convs2.2.bias\", \"generator.resblocks.4.convs2.2.weight_g\", \"generator.resblocks.4.convs2.2.weight_v\", \"generator.resblocks.5.convs1.0.bias\", \"generator.resblocks.5.convs1.0.weight_g\", \"generator.resblocks.5.convs1.0.weight_v\", \"generator.resblocks.5.convs1.1.bias\", \"generator.resblocks.5.convs1.1.weight_g\", \"generator.resblocks.5.convs1.1.weight_v\", \"generator.resblocks.5.convs1.2.bias\", \"generator.resblocks.5.convs1.2.weight_g\", \"generator.resblocks.5.convs1.2.weight_v\", \"generator.resblocks.5.convs2.0.bias\", \"generator.resblocks.5.convs2.0.weight_g\", \"generator.resblocks.5.convs2.0.weight_v\", \"generator.resblocks.5.convs2.1.bias\", \"generator.resblocks.5.convs2.1.weight_g\", \"generator.resblocks.5.convs2.1.weight_v\", \"generator.resblocks.5.convs2.2.bias\", \"generator.resblocks.5.convs2.2.weight_g\", \"generator.resblocks.5.convs2.2.weight_v\", \"generator.resblocks.6.convs1.0.bias\", \"generator.resblocks.6.convs1.0.weight_g\", \"generator.resblocks.6.convs1.0.weight_v\", \"generator.resblocks.6.convs1.1.bias\", \"generator.resblocks.6.convs1.1.weight_g\", \"generator.resblocks.6.convs1.1.weight_v\", \"generator.resblocks.6.convs1.2.bias\", \"generator.resblocks.6.convs1.2.weight_g\", \"generator.resblocks.6.convs1.2.weight_v\", \"generator.resblocks.6.convs2.0.bias\", \"generator.resblocks.6.convs2.0.weight_g\", \"generator.resblocks.6.convs2.0.weight_v\", \"generator.resblocks.6.convs2.1.bias\", \"generator.resblocks.6.convs2.1.weight_g\", \"generator.resblocks.6.convs2.1.weight_v\", \"generator.resblocks.6.convs2.2.bias\", \"generator.resblocks.6.convs2.2.weight_g\", \"generator.resblocks.6.convs2.2.weight_v\", \"generator.resblocks.7.convs1.0.bias\", \"generator.resblocks.7.convs1.0.weight_g\", \"generator.resblocks.7.convs1.0.weight_v\", \"generator.resblocks.7.convs1.1.bias\", \"generator.resblocks.7.convs1.1.weight_g\", \"generator.resblocks.7.convs1.1.weight_v\", \"generator.resblocks.7.convs1.2.bias\", \"generator.resblocks.7.convs1.2.weight_g\", \"generator.resblocks.7.convs1.2.weight_v\", \"generator.resblocks.7.convs2.0.bias\", \"generator.resblocks.7.convs2.0.weight_g\", \"generator.resblocks.7.convs2.0.weight_v\", \"generator.resblocks.7.convs2.1.bias\", \"generator.resblocks.7.convs2.1.weight_g\", \"generator.resblocks.7.convs2.1.weight_v\", \"generator.resblocks.7.convs2.2.bias\", \"generator.resblocks.7.convs2.2.weight_g\", \"generator.resblocks.7.convs2.2.weight_v\", \"generator.resblocks.8.convs1.0.bias\", \"generator.resblocks.8.convs1.0.weight_g\", \"generator.resblocks.8.convs1.0.weight_v\", \"generator.resblocks.8.convs1.1.bias\", \"generator.resblocks.8.convs1.1.weight_g\", \"generator.resblocks.8.convs1.1.weight_v\", \"generator.resblocks.8.convs1.2.bias\", \"generator.resblocks.8.convs1.2.weight_g\", \"generator.resblocks.8.convs1.2.weight_v\", \"generator.resblocks.8.convs2.0.bias\", \"generator.resblocks.8.convs2.0.weight_g\", \"generator.resblocks.8.convs2.0.weight_v\", \"generator.resblocks.8.convs2.1.bias\", \"generator.resblocks.8.convs2.1.weight_g\", \"generator.resblocks.8.convs2.1.weight_v\", \"generator.resblocks.8.convs2.2.bias\", \"generator.resblocks.8.convs2.2.weight_g\", \"generator.resblocks.8.convs2.2.weight_v\", \"generator.resblocks.9.convs1.0.bias\", \"generator.resblocks.9.convs1.0.weight_g\", \"generator.resblocks.9.convs1.0.weight_v\", \"generator.resblocks.9.convs1.1.bias\", \"generator.resblocks.9.convs1.1.weight_g\", \"generator.resblocks.9.convs1.1.weight_v\", \"generator.resblocks.9.convs1.2.bias\", \"generator.resblocks.9.convs1.2.weight_g\", \"generator.resblocks.9.convs1.2.weight_v\", \"generator.resblocks.9.convs2.0.bias\", \"generator.resblocks.9.convs2.0.weight_g\", \"generator.resblocks.9.convs2.0.weight_v\", \"generator.resblocks.9.convs2.1.bias\", \"generator.resblocks.9.convs2.1.weight_g\", \"generator.resblocks.9.convs2.1.weight_v\", \"generator.resblocks.9.convs2.2.bias\", \"generator.resblocks.9.convs2.2.weight_g\", \"generator.resblocks.9.convs2.2.weight_v\", \"generator.resblocks.10.convs1.0.bias\", \"generator.resblocks.10.convs1.0.weight_g\", \"generator.resblocks.10.convs1.0.weight_v\", \"generator.resblocks.10.convs1.1.bias\", \"generator.resblocks.10.convs1.1.weight_g\", \"generator.resblocks.10.convs1.1.weight_v\", \"generator.resblocks.10.convs1.2.bias\", \"generator.resblocks.10.convs1.2.weight_g\", \"generator.resblocks.10.convs1.2.weight_v\", \"generator.resblocks.10.convs2.0.bias\", \"generator.resblocks.10.convs2.0.weight_g\", \"generator.resblocks.10.convs2.0.weight_v\", \"generator.resblocks.10.convs2.1.bias\", \"generator.resblocks.10.convs2.1.weight_g\", \"generator.resblocks.10.convs2.1.weight_v\", \"generator.resblocks.10.convs2.2.bias\", \"generator.resblocks.10.convs2.2.weight_g\", \"generator.resblocks.10.convs2.2.weight_v\", \"generator.resblocks.11.convs1.0.bias\", \"generator.resblocks.11.convs1.0.weight_g\", \"generator.resblocks.11.convs1.0.weight_v\", \"generator.resblocks.11.convs1.1.bias\", \"generator.resblocks.11.convs1.1.weight_g\", \"generator.resblocks.11.convs1.1.weight_v\", \"generator.resblocks.11.convs1.2.bias\", \"generator.resblocks.11.convs1.2.weight_g\", \"generator.resblocks.11.convs1.2.weight_v\", \"generator.resblocks.11.convs2.0.bias\", \"generator.resblocks.11.convs2.0.weight_g\", \"generator.resblocks.11.convs2.0.weight_v\", \"generator.resblocks.11.convs2.1.bias\", \"generator.resblocks.11.convs2.1.weight_g\", \"generator.resblocks.11.convs2.1.weight_v\", \"generator.resblocks.11.convs2.2.bias\", \"generator.resblocks.11.convs2.2.weight_g\", \"generator.resblocks.11.convs2.2.weight_v\", \"generator.conv_post.bias\", \"generator.conv_post.weight_g\", \"generator.conv_post.weight_v\", \"encoder.conv_pre.bias\", \"encoder.conv_pre.weight_g\", \"encoder.conv_pre.weight_v\", \"encoder.normalize.0.weight\", \"encoder.normalize.0.bias\", \"encoder.normalize.1.weight\", \"encoder.normalize.1.bias\", \"encoder.normalize.2.weight\", \"encoder.normalize.2.bias\", \"encoder.normalize.3.weight\", \"encoder.normalize.3.bias\", \"encoder.normalize.4.weight\", \"encoder.normalize.4.bias\", \"encoder.normalize.5.weight\", \"encoder.normalize.5.bias\", \"encoder.normalize.6.weight\", \"encoder.normalize.6.bias\", \"encoder.normalize.7.weight\", \"encoder.normalize.7.bias\", \"encoder.normalize.8.weight\", \"encoder.normalize.8.bias\", \"encoder.normalize.9.weight\", \"encoder.normalize.9.bias\", \"encoder.normalize.10.weight\", \"encoder.normalize.10.bias\", \"encoder.normalize.11.weight\", \"encoder.normalize.11.bias\", \"encoder.ups.0.bias\", \"encoder.ups.0.weight_g\", \"encoder.ups.0.weight_v\", \"encoder.ups.1.bias\", \"encoder.ups.1.weight_g\", \"encoder.ups.1.weight_v\", \"encoder.ups.2.bias\", \"encoder.ups.2.weight_g\", \"encoder.ups.2.weight_v\", \"encoder.ups.3.bias\", \"encoder.ups.3.weight_g\", \"encoder.ups.3.weight_v\", \"encoder.resblocks.0.convs1.0.bias\", \"encoder.resblocks.0.convs1.0.weight_g\", \"encoder.resblocks.0.convs1.0.weight_v\", \"encoder.resblocks.0.convs1.1.bias\", \"encoder.resblocks.0.convs1.1.weight_g\", \"encoder.resblocks.0.convs1.1.weight_v\", \"encoder.resblocks.0.convs1.2.bias\", \"encoder.resblocks.0.convs1.2.weight_g\", \"encoder.resblocks.0.convs1.2.weight_v\", \"encoder.resblocks.0.convs2.0.bias\", \"encoder.resblocks.0.convs2.0.weight_g\", \"encoder.resblocks.0.convs2.0.weight_v\", \"encoder.resblocks.0.convs2.1.bias\", \"encoder.resblocks.0.convs2.1.weight_g\", \"encoder.resblocks.0.convs2.1.weight_v\", \"encoder.resblocks.0.convs2.2.bias\", \"encoder.resblocks.0.convs2.2.weight_g\", \"encoder.resblocks.0.convs2.2.weight_v\", \"encoder.resblocks.1.convs1.0.bias\", \"encoder.resblocks.1.convs1.0.weight_g\", \"encoder.resblocks.1.convs1.0.weight_v\", \"encoder.resblocks.1.convs1.1.bias\", \"encoder.resblocks.1.convs1.1.weight_g\", \"encoder.resblocks.1.convs1.1.weight_v\", \"encoder.resblocks.1.convs1.2.bias\", \"encoder.resblocks.1.convs1.2.weight_g\", \"encoder.resblocks.1.convs1.2.weight_v\", \"encoder.resblocks.1.convs2.0.bias\", \"encoder.resblocks.1.convs2.0.weight_g\", \"encoder.resblocks.1.convs2.0.weight_v\", \"encoder.resblocks.1.convs2.1.bias\", \"encoder.resblocks.1.convs2.1.weight_g\", \"encoder.resblocks.1.convs2.1.weight_v\", \"encoder.resblocks.1.convs2.2.bias\", \"encoder.resblocks.1.convs2.2.weight_g\", \"encoder.resblocks.1.convs2.2.weight_v\", \"encoder.resblocks.2.convs1.0.bias\", \"encoder.resblocks.2.convs1.0.weight_g\", \"encoder.resblocks.2.convs1.0.weight_v\", \"encoder.resblocks.2.convs1.1.bias\", \"encoder.resblocks.2.convs1.1.weight_g\", \"encoder.resblocks.2.convs1.1.weight_v\", \"encoder.resblocks.2.convs1.2.bias\", \"encoder.resblocks.2.convs1.2.weight_g\", \"encoder.resblocks.2.convs1.2.weight_v\", \"encoder.resblocks.2.convs2.0.bias\", \"encoder.resblocks.2.convs2.0.weight_g\", \"encoder.resblocks.2.convs2.0.weight_v\", \"encoder.resblocks.2.convs2.1.bias\", \"encoder.resblocks.2.convs2.1.weight_g\", \"encoder.resblocks.2.convs2.1.weight_v\", \"encoder.resblocks.2.convs2.2.bias\", \"encoder.resblocks.2.convs2.2.weight_g\", \"encoder.resblocks.2.convs2.2.weight_v\", \"encoder.resblocks.3.convs1.0.bias\", \"encoder.resblocks.3.convs1.0.weight_g\", \"encoder.resblocks.3.convs1.0.weight_v\", \"encoder.resblocks.3.convs1.1.bias\", \"encoder.resblocks.3.convs1.1.weight_g\", \"encoder.resblocks.3.convs1.1.weight_v\", \"encoder.resblocks.3.convs1.2.bias\", \"encoder.resblocks.3.convs1.2.weight_g\", \"encoder.resblocks.3.convs1.2.weight_v\", \"encoder.resblocks.3.convs2.0.bias\", \"encoder.resblocks.3.convs2.0.weight_g\", \"encoder.resblocks.3.convs2.0.weight_v\", \"encoder.resblocks.3.convs2.1.bias\", \"encoder.resblocks.3.convs2.1.weight_g\", \"encoder.resblocks.3.convs2.1.weight_v\", \"encoder.resblocks.3.convs2.2.bias\", \"encoder.resblocks.3.convs2.2.weight_g\", \"encoder.resblocks.3.convs2.2.weight_v\", \"encoder.resblocks.4.convs1.0.bias\", \"encoder.resblocks.4.convs1.0.weight_g\", \"encoder.resblocks.4.convs1.0.weight_v\", \"encoder.resblocks.4.convs1.1.bias\", \"encoder.resblocks.4.convs1.1.weight_g\", \"encoder.resblocks.4.convs1.1.weight_v\", \"encoder.resblocks.4.convs1.2.bias\", \"encoder.resblocks.4.convs1.2.weight_g\", \"encoder.resblocks.4.convs1.2.weight_v\", \"encoder.resblocks.4.convs2.0.bias\", \"encoder.resblocks.4.convs2.0.weight_g\", \"encoder.resblocks.4.convs2.0.weight_v\", \"encoder.resblocks.4.convs2.1.bias\", \"encoder.resblocks.4.convs2.1.weight_g\", \"encoder.resblocks.4.convs2.1.weight_v\", \"encoder.resblocks.4.convs2.2.bias\", \"encoder.resblocks.4.convs2.2.weight_g\", \"encoder.resblocks.4.convs2.2.weight_v\", \"encoder.resblocks.5.convs1.0.bias\", \"encoder.resblocks.5.convs1.0.weight_g\", \"encoder.resblocks.5.convs1.0.weight_v\", \"encoder.resblocks.5.convs1.1.bias\", \"encoder.resblocks.5.convs1.1.weight_g\", \"encoder.resblocks.5.convs1.1.weight_v\", \"encoder.resblocks.5.convs1.2.bias\", \"encoder.resblocks.5.convs1.2.weight_g\", \"encoder.resblocks.5.convs1.2.weight_v\", \"encoder.resblocks.5.convs2.0.bias\", \"encoder.resblocks.5.convs2.0.weight_g\", \"encoder.resblocks.5.convs2.0.weight_v\", \"encoder.resblocks.5.convs2.1.bias\", \"encoder.resblocks.5.convs2.1.weight_g\", \"encoder.resblocks.5.convs2.1.weight_v\", \"encoder.resblocks.5.convs2.2.bias\", \"encoder.resblocks.5.convs2.2.weight_g\", \"encoder.resblocks.5.convs2.2.weight_v\", \"encoder.resblocks.6.convs1.0.bias\", \"encoder.resblocks.6.convs1.0.weight_g\", \"encoder.resblocks.6.convs1.0.weight_v\", \"encoder.resblocks.6.convs1.1.bias\", \"encoder.resblocks.6.convs1.1.weight_g\", \"encoder.resblocks.6.convs1.1.weight_v\", \"encoder.resblocks.6.convs1.2.bias\", \"encoder.resblocks.6.convs1.2.weight_g\", \"encoder.resblocks.6.convs1.2.weight_v\", \"encoder.resblocks.6.convs2.0.bias\", \"encoder.resblocks.6.convs2.0.weight_g\", \"encoder.resblocks.6.convs2.0.weight_v\", \"encoder.resblocks.6.convs2.1.bias\", \"encoder.resblocks.6.convs2.1.weight_g\", \"encoder.resblocks.6.convs2.1.weight_v\", \"encoder.resblocks.6.convs2.2.bias\", \"encoder.resblocks.6.convs2.2.weight_g\", \"encoder.resblocks.6.convs2.2.weight_v\", \"encoder.resblocks.7.convs1.0.bias\", \"encoder.resblocks.7.convs1.0.weight_g\", \"encoder.resblocks.7.convs1.0.weight_v\", \"encoder.resblocks.7.convs1.1.bias\", \"encoder.resblocks.7.convs1.1.weight_g\", \"encoder.resblocks.7.convs1.1.weight_v\", \"encoder.resblocks.7.convs1.2.bias\", \"encoder.resblocks.7.convs1.2.weight_g\", \"encoder.resblocks.7.convs1.2.weight_v\", \"encoder.resblocks.7.convs2.0.bias\", \"encoder.resblocks.7.convs2.0.weight_g\", \"encoder.resblocks.7.convs2.0.weight_v\", \"encoder.resblocks.7.convs2.1.bias\", \"encoder.resblocks.7.convs2.1.weight_g\", \"encoder.resblocks.7.convs2.1.weight_v\", \"encoder.resblocks.7.convs2.2.bias\", \"encoder.resblocks.7.convs2.2.weight_g\", \"encoder.resblocks.7.convs2.2.weight_v\", \"encoder.resblocks.8.convs1.0.bias\", \"encoder.resblocks.8.convs1.0.weight_g\", \"encoder.resblocks.8.convs1.0.weight_v\", \"encoder.resblocks.8.convs1.1.bias\", \"encoder.resblocks.8.convs1.1.weight_g\", \"encoder.resblocks.8.convs1.1.weight_v\", \"encoder.resblocks.8.convs1.2.bias\", \"encoder.resblocks.8.convs1.2.weight_g\", \"encoder.resblocks.8.convs1.2.weight_v\", \"encoder.resblocks.8.convs2.0.bias\", \"encoder.resblocks.8.convs2.0.weight_g\", \"encoder.resblocks.8.convs2.0.weight_v\", \"encoder.resblocks.8.convs2.1.bias\", \"encoder.resblocks.8.convs2.1.weight_g\", \"encoder.resblocks.8.convs2.1.weight_v\", \"encoder.resblocks.8.convs2.2.bias\", \"encoder.resblocks.8.convs2.2.weight_g\", \"encoder.resblocks.8.convs2.2.weight_v\", \"encoder.resblocks.9.convs1.0.bias\", \"encoder.resblocks.9.convs1.0.weight_g\", \"encoder.resblocks.9.convs1.0.weight_v\", \"encoder.resblocks.9.convs1.1.bias\", \"encoder.resblocks.9.convs1.1.weight_g\", \"encoder.resblocks.9.convs1.1.weight_v\", \"encoder.resblocks.9.convs1.2.bias\", \"encoder.resblocks.9.convs1.2.weight_g\", \"encoder.resblocks.9.convs1.2.weight_v\", \"encoder.resblocks.9.convs2.0.bias\", \"encoder.resblocks.9.convs2.0.weight_g\", \"encoder.resblocks.9.convs2.0.weight_v\", \"encoder.resblocks.9.convs2.1.bias\", \"encoder.resblocks.9.convs2.1.weight_g\", \"encoder.resblocks.9.convs2.1.weight_v\", \"encoder.resblocks.9.convs2.2.bias\", \"encoder.resblocks.9.convs2.2.weight_g\", \"encoder.resblocks.9.convs2.2.weight_v\", \"encoder.resblocks.10.convs1.0.bias\", \"encoder.resblocks.10.convs1.0.weight_g\", \"encoder.resblocks.10.convs1.0.weight_v\", \"encoder.resblocks.10.convs1.1.bias\", \"encoder.resblocks.10.convs1.1.weight_g\", \"encoder.resblocks.10.convs1.1.weight_v\", \"encoder.resblocks.10.convs1.2.bias\", \"encoder.resblocks.10.convs1.2.weight_g\", \"encoder.resblocks.10.convs1.2.weight_v\", \"encoder.resblocks.10.convs2.0.bias\", \"encoder.resblocks.10.convs2.0.weight_g\", \"encoder.resblocks.10.convs2.0.weight_v\", \"encoder.resblocks.10.convs2.1.bias\", \"encoder.resblocks.10.convs2.1.weight_g\", \"encoder.resblocks.10.convs2.1.weight_v\", \"encoder.resblocks.10.convs2.2.bias\", \"encoder.resblocks.10.convs2.2.weight_g\", \"encoder.resblocks.10.convs2.2.weight_v\", \"encoder.resblocks.11.convs1.0.bias\", \"encoder.resblocks.11.convs1.0.weight_g\", \"encoder.resblocks.11.convs1.0.weight_v\", \"encoder.resblocks.11.convs1.1.bias\", \"encoder.resblocks.11.convs1.1.weight_g\", \"encoder.resblocks.11.convs1.1.weight_v\", \"encoder.resblocks.11.convs1.2.bias\", \"encoder.resblocks.11.convs1.2.weight_g\", \"encoder.resblocks.11.convs1.2.weight_v\", \"encoder.resblocks.11.convs2.0.bias\", \"encoder.resblocks.11.convs2.0.weight_g\", \"encoder.resblocks.11.convs2.0.weight_v\", \"encoder.resblocks.11.convs2.1.bias\", \"encoder.resblocks.11.convs2.1.weight_g\", \"encoder.resblocks.11.convs2.1.weight_v\", \"encoder.resblocks.11.convs2.2.bias\", \"encoder.resblocks.11.convs2.2.weight_g\", \"encoder.resblocks.11.convs2.2.weight_v\", \"encoder.conv_post.weight\", \"encoder.conv_post.bias\". \n\tUnexpected key(s) in state_dict: \"generator\", \"encoder\", \"quantizer\". "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import json\n",
    "from academicodec.models.hificodec.vqvae import VQVAE\n",
    "\n",
    "# Paths to the configuration and pre-trained model\n",
    "config_path = \"/data/lekha_codec_model_files/AcademiCodec/egs/HiFi-Codec-24k-240d/config_24k_240d.json\"\n",
    "model_path = \"/data/lekha_codec_model_files/AcademiCodec/egs/HiFi-Codec-24k-240d/model.pt\"\n",
    "\n",
    "# Load the configuration\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Initialize the VQVAE model\n",
    "vqvae = VQVAE(config_path, model_path, with_encoder=True)\n",
    "vqvae.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "vqvae.eval()\n",
    "\n",
    "# Input audio path\n",
    "audio_path = \"/home/lekhab/AudioDeepfake/sample_9.wav\"\n",
    "\n",
    "# # Load and preprocess the audio\n",
    "# wav, sr = torchaudio.load(audio_path)\n",
    "\n",
    "# # Ensure the audio is monophonic\n",
    "# if wav.shape[0] > 1:\n",
    "#     wav = wav[:1, :]  # Use the first channel\n",
    "\n",
    "# # Resample if necessary\n",
    "# model_sample_rate = config[\"sample_rate\"]\n",
    "# if sr != model_sample_rate:\n",
    "#     wav = torchaudio.functional.resample(wav, sr, model_sample_rate)\n",
    "\n",
    "# # Normalize the audio\n",
    "# wav = wav / wav.abs().max()\n",
    "\n",
    "# # Add batch dimension\n",
    "# wav = wav.unsqueeze(0)\n",
    "\n",
    "# # Encode the audio to latent codes\n",
    "# with torch.no_grad():\n",
    "#     vq_codes = vqvae.encode(wav)\n",
    "\n",
    "# # Decode the latent codes back into audio\n",
    "# with torch.no_grad():\n",
    "#     reconstructed_audio = vqvae(vq_codes)\n",
    "\n",
    "# # Remove batch dimension and clamp to valid audio range\n",
    "# reconstructed_audio = reconstructed_audio.squeeze(0).clamp(-1.0, 1.0)\n",
    "\n",
    "# # Save the reconstructed audio\n",
    "# output_path = \"/home/lekhab/AudioDeepfake/sample_reconstructed.wav\"\n",
    "# torchaudio.save(output_path, reconstructed_audio, model_sample_rate)\n",
    "\n",
    "# print(f\"Reconstructed audio saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lekhab/AudioDeepfake/AcademiCodec/academicodec/models/hificodec/vqvae.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path)\n",
      "/home/lekhab/.conda/envs/codec_fake/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for file: sample_9\n",
      "Shape of extracted features: torch.Size([1, 1000, 4])\n",
      "Reconstructed audio saved to: academicodec_reconstructed_audio1.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from academicodec.models.hificodec.vqvae_tester import VqvaeTester\n",
    "\n",
    "# Set paths\n",
    "config_path = \"/data/lekha_codec_model_files/AcademiCodec/egs/HiFi-Codec-24k-240d/config_24k_240d.json\"\n",
    "model_path = \"/data/lekha_codec_model_files/AcademiCodec/egs/HiFi-Codec-24k-240d/model.pt\"\n",
    "audio_path = \"sample_9.wav\"\n",
    "output_path = \"academicodec_reconstructed_audio1.wav\"\n",
    "\n",
    "# Initialize the VqvaeTester\n",
    "vqvae_tester = VqvaeTester(config_path, model_path, sample_rate=24000)\n",
    "vqvae_tester.cuda()  # Move to GPU if available\n",
    "\n",
    "# Extract features/latents\n",
    "fid, vq_codes = vqvae_tester.vq(audio_path)\n",
    "print(f\"Extracted features for file: {fid}\")\n",
    "print(f\"Shape of extracted features: {vq_codes.shape}\")\n",
    "\n",
    "# Regenerate audio from features\n",
    "_, reconstructed_audio = vqvae_tester.forward(audio_path)\n",
    "\n",
    "# Convert to CPU and remove batch dimension\n",
    "reconstructed_audio = reconstructed_audio.cpu().squeeze(0)\n",
    "\n",
    "# Save the reconstructed audio\n",
    "torchaudio.save(output_path, reconstructed_audio, 24000)\n",
    "print(f\"Reconstructed audio saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create spectograms for input and output audio files\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_spectrogram(audio_file, title):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    \n",
    "    # Compute the STFT and convert to decibel scale\n",
    "    stft = librosa.stft(y)\n",
    "    spectrogram = librosa.amplitude_to_db(abs(stft))\n",
    "    \n",
    "    # Plot the spectrogram\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spectrogram, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_spectrogram_difference(audio_file1, audio_file2):\n",
    "    # Load and compute spectrograms for both audio files\n",
    "    y1, sr1 = librosa.load(audio_file1)\n",
    "    y2, sr2 = librosa.load(audio_file2)\n",
    "    \n",
    "    if sr1 != sr2:\n",
    "        raise ValueError(\"Sample rates of the two audio files do not match. Please resample to the same rate.\")\n",
    "    \n",
    "    # Compute the STFT for both signals\n",
    "    stft1 = librosa.stft(y1)\n",
    "    stft2 = librosa.stft(y2)\n",
    "    \n",
    "    # Convert to decibel scale\n",
    "    spectrogram1 = librosa.amplitude_to_db(abs(stft1))\n",
    "    spectrogram2 = librosa.amplitude_to_db(abs(stft2))\n",
    "    \n",
    "    # Compute the difference between the two spectrograms\n",
    "    spectrogram_diff = spectrogram1 - spectrogram2\n",
    "    \n",
    "    # Plot the difference\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spectrogram_diff, sr=sr1, x_axis='time', y_axis='log', cmap='coolwarm')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(\"Difference between Spectrograms\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# File paths for the two audio files\n",
    "audio_file1 = 'sample_9.wav'  # original audio\n",
    "audio_file2 = 'academicodec_reconstructed_audio.wav'  # output audio file from dac\n",
    "\n",
    "# Plot spectrograms for both files\n",
    "plot_spectrogram(audio_file1, title=\"Spectrogram of Original audio\")\n",
    "# plot_spectrogram(audio_file2, title=\"Spectrogram of academicodec generated audio\")\n",
    "# plot_spectrogram_difference(audio_file1, audio_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create spectograms for input and output audio files\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_spectrogram(audio_file, title):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    \n",
    "    # Compute the STFT and convert to decibel scale\n",
    "    stft = librosa.stft(y)\n",
    "    spectrogram = librosa.amplitude_to_db(abs(stft))\n",
    "    \n",
    "    # Plot the spectrogram\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spectrogram, sr=sr, x_axis='time', y_axis='log', cmap='viridis')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_spectrogram_difference(audio_file1, audio_file2):\n",
    "    # Load and compute spectrograms for both audio files\n",
    "    y1, sr1 = librosa.load(audio_file1)\n",
    "    y2, sr2 = librosa.load(audio_file2)\n",
    "    \n",
    "    if sr1 != sr2:\n",
    "        raise ValueError(\"Sample rates of the two audio files do not match. Please resample to the same rate.\")\n",
    "    \n",
    "    # Compute the STFT for both signals\n",
    "    stft1 = librosa.stft(y1)\n",
    "    stft2 = librosa.stft(y2)\n",
    "    \n",
    "    # Convert to decibel scale\n",
    "    spectrogram1 = librosa.amplitude_to_db(abs(stft1))\n",
    "    spectrogram2 = librosa.amplitude_to_db(abs(stft2))\n",
    "    \n",
    "    # Compute the difference between the two spectrograms\n",
    "    spectrogram_diff = spectrogram1 - spectrogram2\n",
    "    \n",
    "    # Plot the difference\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spectrogram_diff, sr=sr1, x_axis='time', y_axis='log', cmap='coolwarm')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(\"Difference between Spectrograms\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# File paths for the two audio files\n",
    "audio_file1 = 'sample_9.wav'  # original audio\n",
    "audio_file2 = 'encodec_decoded_audio.wav'  # output audio file from dac\n",
    "\n",
    "# Plot spectrograms for both files\n",
    "plot_spectrogram(audio_file1, title=\"Spectrogram of Original audio\")\n",
    "plot_spectrogram(audio_file2, title=\"Spectrogram of encodec generated audio\")\n",
    "plot_spectrogram_difference(audio_file1, audio_file2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codec_fake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AudioDec Codec\n",
    "https://github.com/facebookresearch/AudioDec\n",
    "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10096509\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install git+https://github.com/voidful/AudioDec.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lekhab/.conda/envs/codec_fake/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nlp2\n",
    "# download encoder\n",
    "nlp2.download_file(\n",
    "    'https://huggingface.co/AudioDecBenchmark/AudioDec/resolve/main/autoencoder/symAD_libritts_24000_hop300/checkpoint-500000steps.pkl',\n",
    "    'audiodec_autoencoder_24k_320d')\n",
    "nlp2.download_file(\n",
    "    'https://huggingface.co/AudioDecBenchmark/AudioDec/resolve/main/autoencoder/symAD_libritts_24000_hop300/config.yml',\n",
    "    \"audiodec_autoencoder_24k_320d\")\n",
    "encoder_config_path = \"audiodec_autoencoder_24k_320d/checkpoint-500000steps.pkl\"\n",
    "\n",
    "# download decoder\n",
    "nlp2.download_file(\n",
    "    'https://huggingface.co/AudioDecBenchmark/AudioDec/resolve/main/vocoder/AudioDec_v1_symAD_libritts_24000_hop300_clean/checkpoint-500000steps.pkl',\n",
    "    'audiodec_vocoder_24k_320d')\n",
    "nlp2.download_file(\n",
    "    'https://huggingface.co/AudioDecBenchmark/AudioDec/resolve/main/vocoder/AudioDec_v1_symAD_libritts_24000_hop300_clean/config.yml',\n",
    "    \"audiodec_vocoder_24k_320d\")\n",
    "nlp2.download_file(\n",
    "    \"https://huggingface.co/AudioDecBenchmark/AudioDec/resolve/main/vocoder/AudioDec_v1_symAD_libritts_24000_hop300_clean/symAD_libritts_24000_hop300_clean.npy\",\n",
    "    \"audiodec_vocoder_24k_320d\"\n",
    ")\n",
    "decoder_config_path = \"audiodec_vocoder_24k_320d/checkpoint-500000steps.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Load audio signal file\n",
    "male_voice_file_path = os.path.join(current_dir, \"sample_9.wav\")\n",
    "female_voice_file_path = os.path.join(current_dir, \"female_voice.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "# All rights reserved.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from AudioDec.utils.audiodec import AudioDec, assign_model\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# audio file_path\n",
    "file_path = os.path.join(current_dir, \"sample_9.wav\")\n",
    "\n",
    "\n",
    "def process_audio(input_file, output_file, model_name=\"vctk_v1\", cuda_device=0, num_threads=4):\n",
    "    \"\"\"\n",
    "    Encode and decode an audio file using the AudioDec model.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input .wav file.\n",
    "        output_file (str): Path to save the output .wav file.\n",
    "        model_name (str): Name of the AudioDec model to use (default: vctk_v1).\n",
    "        cuda_device (int): CUDA device index (-1 for CPU, 0 or higher for GPU).\n",
    "        num_threads (int): Number of threads for computation.\n",
    "    \"\"\"\n",
    "    # Assign devices\n",
    "    if cuda_device < 0:\n",
    "        tx_device = \"cpu\"\n",
    "        rx_device = \"cpu\"\n",
    "    else:\n",
    "        tx_device = f\"cuda:{cuda_device}\"\n",
    "        rx_device = f\"cuda:{cuda_device}\"\n",
    "    torch.set_num_threads(num_threads)\n",
    "\n",
    "    # Assign model\n",
    "    sample_rate, encoder_checkpoint, decoder_checkpoint = assign_model(model_name)\n",
    "\n",
    "    # Initialize AudioDec\n",
    "    print(\"Initializing AudioDec...\")\n",
    "    audiodec = AudioDec(tx_device=tx_device, rx_device=rx_device)\n",
    "    audiodec.load_transmitter(encoder_checkpoint)\n",
    "    audiodec.load_receiver(encoder_checkpoint, decoder_checkpoint)\n",
    "\n",
    "    # Process audio\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"Input file {input_file} does not exist!\")\n",
    "\n",
    "    data, fs = sf.read(input_file, always_2d=True)\n",
    "    if fs != sample_rate:\n",
    "        raise ValueError(f\"Input sample rate ({fs}Hz) does not match model sample rate ({sample_rate}Hz)!\")\n",
    "\n",
    "    x = np.expand_dims(data.transpose(1, 0), axis=1)  # (T, C) -> (C, 1, T)\n",
    "    x = torch.tensor(x, dtype=torch.float).to(tx_device)\n",
    "\n",
    "    print(\"Encoding and decoding the audio...\")\n",
    "    with torch.no_grad():\n",
    "        z = audiodec.tx_encoder.encode(x)\n",
    "        idx = audiodec.tx_encoder.quantize(z)\n",
    "        zq = audiodec.rx_encoder.lookup(idx)\n",
    "        y = audiodec.decoder.decode(zq)[:, :, :x.size(-1)]\n",
    "        y = y.squeeze(1).transpose(1, 0).cpu().numpy()  # (T, C)\n",
    "\n",
    "    # Save the output audio\n",
    "    sf.write(output_file, y, fs, \"PCM_16\")\n",
    "    print(f\"Processed audio saved to {output_file}!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Process audio using AudioDec model.\")\n",
    "    parser.add_argument(\"-i\", \"--input\", type=str, required=True, help=\"Path to input .wav file\")\n",
    "    parser.add_argument(\"-o\", \"--output\", type=str, required=True, help=\"Path to output .wav file\")\n",
    "    parser.add_argument(\"--model\", type=str, default=\"vctk_v1\", help=\"Model to use (default: vctk_v1)\")\n",
    "    parser.add_argument(\"--cuda\", type=int, default=0, help=\"CUDA device index (-1 for CPU, default: 0)\")\n",
    "    parser.add_argument(\"--num_threads\", type=int, default=4, help=\"Number of threads (default: 4)\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    process_audio(\n",
    "        input_file=args.input,\n",
    "        output_file=args.output,\n",
    "        model_name=args.model,\n",
    "        cuda_device=args.cuda,\n",
    "        num_threads=args.num_threads,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codec_fake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
